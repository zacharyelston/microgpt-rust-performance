MicroGPT: 4192 params, training for 3000 steps (lr=0.005, emb=16, head=4, layer=1)
step    0 | loss 3.2320step   20 | loss 2.8128step   40 | loss 2.4858step   60 | loss 2.4049step   80 | loss 2.6194step  100 | loss 2.9500step  120 | loss 2.7228step  140 | loss 2.5364step  160 | loss 2.1596step  180 | loss 2.2997step  200 | loss 3.2568step  220 | loss 2.1047step  240 | loss 2.9826step  260 | loss 2.4159step  280 | loss 2.8621step  300 | loss 1.6162step  320 | loss 1.7757step  340 | loss 2.3528step  360 | loss 2.6962step  380 | loss 1.8732step  400 | loss 2.4333step  420 | loss 1.9215step  440 | loss 2.4088step  460 | loss 2.2733step  480 | loss 2.7960step  500 | loss 1.8022step  520 | loss 2.3480step  540 | loss 1.8399step  560 | loss 1.8193step  580 | loss 1.7203step  600 | loss 2.4632step  620 | loss 3.1379step  640 | loss 2.5482step  660 | loss 3.2695step  680 | loss 1.5986step  700 | loss 1.6568step  720 | loss 1.7786step  740 | loss 1.5092step  760 | loss 2.6875step  780 | loss 1.8118step  800 | loss 2.0532step  820 | loss 1.9918step  840 | loss 2.0201step  860 | loss 1.9962step  880 | loss 2.6305step  900 | loss 3.0732step  920 | loss 2.0600step  940 | loss 1.9657step  960 | loss 2.1377step  980 | loss 2.4968step 1000 | loss 2.3161step 1020 | loss 2.3244step 1040 | loss 2.5958step 1060 | loss 2.5731step 1080 | loss 1.8586step 1100 | loss 1.7803step 1120 | loss 2.0507step 1140 | loss 2.3125step 1160 | loss 2.2279step 1180 | loss 2.1221step 1200 | loss 2.3155step 1220 | loss 2.9071step 1240 | loss 1.8731step 1260 | loss 1.8872step 1280 | loss 2.3738step 1300 | loss 2.2411step 1320 | loss 2.6162step 1340 | loss 2.2070step 1360 | loss 2.4850step 1380 | loss 2.5973step 1400 | loss 1.8376step 1420 | loss 2.4031step 1440 | loss 1.8218step 1460 | loss 1.8471step 1480 | loss 2.1321step 1500 | loss 1.6742step 1520 | loss 2.2553step 1540 | loss 2.1204step 1560 | loss 1.9450step 1580 | loss 1.4852step 1600 | loss 2.5641step 1620 | loss 1.9884step 1640 | loss 2.2148step 1660 | loss 2.2967step 1680 | loss 1.8244step 1700 | loss 2.7612step 1720 | loss 2.3044step 1740 | loss 1.6190step 1760 | loss 2.4848step 1780 | loss 2.6552step 1800 | loss 2.8016step 1820 | loss 1.8669step 1840 | loss 2.2249step 1860 | loss 1.6346step 1880 | loss 2.3367step 1900 | loss 3.2676step 1920 | loss 2.3335step 1940 | loss 1.5596step 1960 | loss 2.7484step 1980 | loss 2.1767step 2000 | loss 2.4175step 2020 | loss 2.1644step 2040 | loss 2.3958step 2060 | loss 1.8358step 2080 | loss 2.7011step 2100 | loss 1.6298step 2120 | loss 2.1654step 2140 | loss 2.2749step 2160 | loss 1.7564step 2180 | loss 3.0049step 2200 | loss 2.6553step 2220 | loss 2.5901step 2240 | loss 2.4992step 2260 | loss 2.0013step 2280 | loss 2.1020step 2300 | loss 1.8880step 2320 | loss 2.5555step 2340 | loss 1.9436step 2360 | loss 1.9892step 2380 | loss 1.8469step 2400 | loss 3.4718step 2420 | loss 2.3737step 2440 | loss 1.7404step 2460 | loss 2.1958step 2480 | loss 1.7783step 2500 | loss 2.1118step 2520 | loss 2.3633step 2540 | loss 1.9104step 2560 | loss 2.1107step 2580 | loss 1.6237step 2600 | loss 2.2438step 2620 | loss 2.2205step 2640 | loss 2.1606step 2660 | loss 2.1866step 2680 | loss 2.3027step 2700 | loss 1.9070step 2720 | loss 2.0776step 2740 | loss 2.4480step 2760 | loss 1.5465step 2780 | loss 1.8701step 2800 | loss 2.7711step 2820 | loss 2.2631step 2840 | loss 2.4611step 2860 | loss 1.7852step 2880 | loss 2.5618step 2900 | loss 2.1005step 2920 | loss 1.9799step 2940 | loss 2.0204step 2960 | loss 1.9684step 2980 | loss 2.4750
--- Generation ---
> mani
> erina
> jolen
> bebra
> alixa
